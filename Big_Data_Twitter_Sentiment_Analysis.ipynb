{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Big_Data_Twitter_Sentiment_Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YixinFan11/Big-Data-Tweeter-Sentiment-Analysis/blob/master/Big_Data_Twitter_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading the data from Kaggle"
      ],
      "metadata": {
        "id": "sYCL7wB5Fh0C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOYJg_BsDDmW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaa8089f-46c6-40a8-fd5d-cfb16a7bec73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ],
      "source": [
        "## Prerequisites\n",
        "#!pip install kaggle --upgrade\n",
        "#!cp kaggle.json ~/.kaggle/\n",
        "#!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "! pip install -q kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Downloading data command\n",
        "!kaggle datasets download -d manchunhui/us-election-2020-tweets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRuQFE-cE7bp",
        "outputId": "b307239e-57cd-4771-db19-2dc2c62c0808"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "us-election-2020-tweets.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir content/data\n",
        "!unzip us-election-2020-tweets.zip -d data"
      ],
      "metadata": {
        "id": "GO1eJ1FDF2uP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d04bcbc9-d7fb-45eb-b37b-e67e655faed5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘content/data’: No such file or directory\n",
            "Archive:  us-election-2020-tweets.zip\n",
            "replace data/hashtag_donaldtrump.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace data/hashtag_joebiden.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Pyspark"
      ],
      "metadata": {
        "id": "Sz3hB6Dc-GX2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark "
      ],
      "metadata": {
        "id": "V_Cs4IN0-Gfj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc9d5eeb-4669-4ed4-8895-faf5dbfb9e51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.7/dist-packages (3.2.1)\n",
            "Requirement already satisfied: py4j==0.10.9.3 in /usr/local/lib/python3.7/dist-packages (from pyspark) (0.10.9.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Header Files"
      ],
      "metadata": {
        "id": "tdwfhe3oFpy-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Python \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns \n",
        "import re\n",
        "\n",
        "\n",
        "# stopwords, tokenizer, stemmer\n",
        "import nltk  \n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.probability import FreqDist\n",
        "\n",
        "# spell correction, lemmatization\n",
        "from textblob import TextBlob\n",
        "from textblob import Word\n",
        "\n",
        "## Spark\n",
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql import Row\n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType, StructField, StringType , FloatType\n",
        "from pyspark.sql.functions import lit\n",
        "from pyspark.sql.functions import regexp_replace\n",
        "from pyspark.sql.functions import udf\n",
        "\n",
        "# Create Spark Session\n",
        "spark = SparkSession.builder.master(\"local[1]\").appName('Twitter Sentiment Analysis').getOrCreate()"
      ],
      "metadata": {
        "id": "Q2PUC_Z2FaEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reading the Data"
      ],
      "metadata": {
        "id": "AYCcYnYLlrdb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Defining the Schema"
      ],
      "metadata": {
        "id": "Zp1PRJSTz9zo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Created the schema that we need \n",
        "# # Fucking Brute Force I dont like it\n",
        "mySchema = StructType([ StructField('created_at', StringType(), True)\\\n",
        "                       ,StructField('tweet_id', FloatType(), True)\\\n",
        "                       ,StructField('tweet',StringType(),True)\\\n",
        "                       ,StructField('likes',FloatType(),True)\\\n",
        "                       ,StructField('retweet_count',FloatType(),True)\\\n",
        "                       ,StructField('source',StringType(),True)\\\n",
        "                       ,StructField('user_id',FloatType(),True)\\\n",
        "                       ,StructField('user_name',StringType(),True)\\\n",
        "                       ,StructField('user_screen_name',StringType(),True)\\\n",
        "                       ,StructField('user_description',StringType(),True)\\\n",
        "                       ,StructField('user_join_date',StringType(),True)\\\n",
        "                       ,StructField('user_followers_count',FloatType(),True)\\\n",
        "                       ,StructField('user_location',StringType(),True)\\\n",
        "                       ,StructField('lat',FloatType(),True)\\\n",
        "                       ,StructField('long',FloatType(),True)\\\n",
        "                       ,StructField('city',StringType(),True)\\\n",
        "                       ,StructField('country',StringType(),True)\\\n",
        "                       ,StructField('continent',StringType(),True)\\\n",
        "                       ,StructField('state',StringType(),True)\\\n",
        "                       ,StructField('state_code',StringType(),True)\\\n",
        "                       ,StructField('collected_at',StringType(),True)\\\n",
        "                       ])"
      ],
      "metadata": {
        "id": "fm82ZCTKz98f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating spark data frame\n",
        "# This shit was so hard to do it was not reading multiline data at first it killed me\n",
        "# Took me 6 hours to figure this shit \n",
        "# Now have to change the schema to different data type\n",
        "\n",
        "trump_df = spark.read.option('multiline',True)\\\n",
        "                     .option('header', 'true')\\\n",
        "                     .option('lineterminator',\"\\n\")\\\n",
        "                     .option('inferSchema', \"true\")\\\n",
        "                     .schema(mySchema)\\\n",
        "                     .csv('/content/data/hashtag_donaldtrump.csv')\n",
        "trump_df.cache()\n",
        "print('Trump DataFrame Schema')\n",
        "trump_df.printSchema()\n",
        "\n",
        "\n",
        "biden_df = spark.read.option('multiline',True)\\\n",
        "                     .option('header', 'true')\\\n",
        "                     .option('lineterminator',\"\\n\")\\\n",
        "                     .option('inferSchema', \"true\")\\\n",
        "                     .schema(mySchema)\\\n",
        "                     .csv('/content/data/hashtag_joebiden.csv')\n",
        "\n",
        "biden_df.cache()\n",
        "print('Biden DataFrame Schema')\n",
        "biden_df.printSchema()"
      ],
      "metadata": {
        "id": "cpeKGK5IH3rG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Trump Data Stats"
      ],
      "metadata": {
        "id": "gxHe27iI6B-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Took me 35 seconds to run\n",
        "trump_df.show(5)"
      ],
      "metadata": {
        "id": "X4nxWpnQjDzd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1bdc257-4dbb-4684-bfe4-15076830e763"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+-------------+--------------------+-----+-------------+------------------+------------+--------------------+----------------+--------------------+-------------------+--------------------+--------------------+---------+-----------+----------+--------------------+-------------+--------------------+----------+--------------------+\n",
            "|         created_at|     tweet_id|               tweet|likes|retweet_count|            source|     user_id|           user_name|user_screen_name|    user_description|     user_join_date|user_followers_count|       user_location|      lat|       long|      city|             country|    continent|               state|state_code|        collected_at|\n",
            "+-------------------+-------------+--------------------+-----+-------------+------------------+------------+--------------------+----------------+--------------------+-------------------+--------------------+--------------------+---------+-----------+----------+--------------------+-------------+--------------------+----------+--------------------+\n",
            "|2020-10-15 00:00:01|1.31652925E18|#Elecciones2020 |...|  0.0|          0.0|         TweetDeck|3.60666528E8|  El Sol Latino News| elsollatinonews|🌐 Noticias de in...|2011-08-23 15:33:45|              1860.0|Philadelphia, PA ...| 25.77427|  -80.19366|      null|United States of ...|North America|             Florida|        FL| 2020-10-21 00:00:00|\n",
            "|2020-10-15 00:00:01|1.31652925E18|Usa 2020, Trump c...| 26.0|          9.0|  Social Mediaset |3.31617632E8|             Tgcom24| MediasetTgcom24|Profilo ufficiale...|2011-07-08 13:12:20|           1067661.0|                null|     null|       null|      null|                null|         null|                null|      null|2020-10-21 00:00:...|\n",
            "|2020-10-15 00:00:02|1.31652925E18|#Trump: As a stud...|  2.0|          1.0|   Twitter Web App|   8436472.0|              snarke|          snarke|Will mock for foo...|2007-08-26 05:56:11|              1185.0|            Portland| 45.52025|-122.674194|  Portland|United States of ...|North America|              Oregon|        OR|2020-10-21 00:00:...|\n",
            "|2020-10-15 00:00:02|1.31652925E18|2 hours since las...|  0.0|          0.0|     Trumpytweeter|8.2835557E17|       Trumpytweeter|   trumpytweeter|If he doesn't twe...|2017-02-05 21:32:17|                32.0|                null|     null|       null|      null|                null|         null|                null|      null|2020-10-21 00:00:...|\n",
            "|2020-10-15 00:00:08|1.31652925E18|You get a tie! An...|  4.0|          3.0|Twitter for iPhone|   4.74138E7|Rana Abtar - رنا ...|       Ranaabtar|Washington Corres...|2009-06-15 19:05:35|              5393.0|       Washington DC|38.894993|  -77.03656|Washington|United States of ...|North America|District of Columbia|        DC|2020-10-21 00:00:...|\n",
            "+-------------------+-------------+--------------------+-----+-------------+------------------+------------+--------------------+----------------+--------------------+-------------------+--------------------+--------------------+---------+-----------+----------+--------------------+-------------+--------------------+----------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Took me 2 minutes to run one command carefull while running\n",
        "trump_df.summary().show()"
      ],
      "metadata": {
        "id": "Pp_hw_UklPSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Biden Data Stats"
      ],
      "metadata": {
        "id": "SK96TGda6FnP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "biden_df.show(5)"
      ],
      "metadata": {
        "id": "k0BjcKm9Va_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Took me 1 minute 21 seconds to run this command carefull while running\n",
        "biden_df.summary().show()"
      ],
      "metadata": {
        "id": "X5FlV8Za4XlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Concatinating Data "
      ],
      "metadata": {
        "id": "_HSBIeJN6_sM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Adding a column to the dataframe \n",
        "trump_df = trump_df.withColumn(\"Candidate\", lit('TRUMP'))\n",
        "trump_df.show()"
      ],
      "metadata": {
        "id": "1sjw5nxc4bRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "biden_df = biden_df.withColumn(\"Candidate\", lit('BIDEN'))\n",
        "biden_df.show()"
      ],
      "metadata": {
        "id": "KbC4koSq8KCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = trump_df.union(biden_df)\n",
        "data.cache()\n",
        "data.show()"
      ],
      "metadata": {
        "id": "4m1vgbR08YFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDA\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "someone please plot graphs for each one of them\n",
        "```"
      ],
      "metadata": {
        "id": "kczyT_jCEi7j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Checking the data imbalance\n",
        "data.groupBy('Candidate').count().withColumnRenamed(\"count\",\"Number of Data\").show()\n",
        "## The dataset is imbalance but not serious(Yixin)"
      ],
      "metadata": {
        "id": "cLGJDlPgC3j6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Comparrsion for the number of tweets\n",
        "data.groupby('Candidate').agg(F.expr('count(tweet)')\\\n",
        "                              .alias('Number of Tweets')).show()\n",
        "## After delete the null value in tweets, the imbalance status does not change too much(Yixin)"
      ],
      "metadata": {
        "id": "H__CBpUBH4AQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# comparison of likes\n",
        "data.groupby('Candidate').agg(F.expr('count(likes)')\\\n",
        "                              .alias('Number of Likes')).show()\n",
        "### Better to add up than just count rows(Yixin)"
      ],
      "metadata": {
        "id": "UDHXUZ3iDjmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Can someone please remove the null that is being shown also show only top 10 rows \n",
        "data.na.drop(subset=[\"Country\"]).show()\n",
        "data.groupby('Country').count()\\\n",
        ".withColumnRenamed('count','Number of Data')\\\n",
        ".sort(F.desc('Number of Data')).show()\n",
        "## dont think this will make any sense, since most of countries are null value(Yixin)"
      ],
      "metadata": {
        "id": "EEF0ijQPFQBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=316181+59192+55419+38786+32820+32245+26411+18524+14201+10284+9829+9147+8352+8287+6556+5259+5136+4229+4041\n",
        "print(x)\n",
        "x1 =data.select('Created_at').count()\n",
        "print(x1)"
      ],
      "metadata": {
        "id": "SQxqLSA1mawk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making USA to US \n",
        "data = data.withColumn('Country', regexp_replace('Country', 'United States of America', 'US'))\n",
        "data = data.withColumn('Country', regexp_replace('Country', 'United States', 'US'))\n",
        "\n",
        "## Make sure by checking the count of the data \n",
        "data.groupby('Country').count()\\\n",
        ".withColumnRenamed('count','Number of Data')\\\n",
        ".sort(F.desc('Number of Data')).show()\n",
        "\n",
        "## dont think this will make any sense, since most of countries are null value(Yixin)"
      ],
      "metadata": {
        "id": "npdv7qvAL42c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing the Data(Tweets)"
      ],
      "metadata": {
        "id": "C690EzEMmYBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "elXOry3-o7_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### TRY this one by your self\n",
        "# Refer to user defined functions for this application\n",
        "text = u' This dog \\U0001f602 <a href=\"https://stackoverflow.com/questions/49840965/how-to-add-hyperlinks-to-strings-in-python\">TIC123</a> '\n",
        "print(text) \n",
        "\n",
        "def preprocess_tweets(text):#, stem=False, lemmatize=False):\n",
        "    # Make everything in lower case\n",
        "    text = text.lower()\n",
        "    # Remove links, special characters , numbers punctuation etc. \n",
        "    # Refer - https://stackoverflow.com/questions/33404752/removing-emojis-from-a-string-in-python \n",
        "    # emoji_pattern = re.compile(\"[\"\n",
        "    #     u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "    #     u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "    #     u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "    #     u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "    #                        \"]+\", flags=re.UNICODE)\n",
        "    # Bottom one is also working try it with the example that I am using \n",
        "    # I will comment this out so you guys can try\n",
        "    chars_and_links= r'\\d+|http?\\S+|[^A-Za-z0-9]+'\n",
        "    text = re.sub(chars_and_links,' ',text)\n",
        "    #text = re.sub(emoji_pattern,' ',text)\n",
        "    return text\n",
        "\n",
        "print(preprocess_tweets(text))"
      ],
      "metadata": {
        "id": "zRZ0vN6quou7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "ps = PorterStemmer()\n",
        "\n",
        "def preprocess_tweets(text, stem=False, lemmatize=False):\n",
        "    ## If statement for fault tolerance\n",
        "    if isinstance(text,str):\n",
        "        text = text.lower()\n",
        "        # Remove links, special characters , numbers punctuation etc. \n",
        "        chars_and_links= r'\\d+|http?\\S+|[^A-Za-z0-9]+'\n",
        "        # Cleaned the text\n",
        "        text = re.sub(chars_and_links,' ',text)\n",
        "\n",
        "        filtered_text = []\n",
        "        # Tokenize the text\n",
        "        words = word_tokenize(text) \n",
        "        # Remove stopwords and stem\n",
        "        for word in words:\n",
        "            # Words in stop words or not\n",
        "            if not word in stop_words:\n",
        "                if stem:\n",
        "                    filtered_text.append(ps.stem(word))\n",
        "                elif lemmatize:\n",
        "                    filtered_text.append(Word(word).lemmatize())\n",
        "                else:\n",
        "                    filtered_text.append(word)\n",
        "        # Return the filtered text\n",
        "        return filtered_text\n",
        "    else:\n",
        "        return text"
      ],
      "metadata": {
        "id": "YXUSrer5nVkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop all the NAN values\n",
        "#data.na.drop(subset=[\"tweet\"]).show()\n",
        "\n",
        "\n",
        "## Now to apply this to the text we need to create a user defined function\n",
        "## Refer https://sparkbyexamples.com/pyspark/pyspark-udf-user-defined-function/\n",
        "\n",
        "## Created my udf\n",
        "Preprocess_UDF = udf(lambda x: preprocess_tweets(x))  \n",
        "# \"marketplace\",\"star_rating\").distinct().show(5)\n",
        "# data = data.select(Preprocess_UDF(F.col(\"tweet\")).alias(\"tweet\")).show(5)\n",
        "#.select([F.col(c).cast('float').alias(c) for c in df.columns])\n",
        "\n",
        "# data = data.select(Preprocess_UDF(F.col('tweet').alias('Tokenized_tweet'))).collect()\n",
        "# data.show()"
      ],
      "metadata": {
        "id": "ptY9mMkds79R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data_res.show(5)"
      ],
      "metadata": {
        "id": "BhbHG8bGwaXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data.show(5)"
      ],
      "metadata": {
        "id": "WadOeVPaz9on"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sentiment_analysis(df):\n",
        "    \n",
        "    # Determine polarity and subjectivity\n",
        "    data['Polarity'] = data['tweetNew'].apply(lambda x: TextBlob(' '.join(x)).sentiment.polarity)\n",
        "    df['Subjectivity'] = df['tweetNew'].apply(lambda x: TextBlob(' '.join(x)).sentiment.subjectivity)\n",
        "    \n",
        "    # Classify overall sentiment\n",
        "    df.loc[df.Polarity > 0,'Sentiment'] = 'positive'\n",
        "    df.loc[df.Polarity == 0,'Sentiment'] = 'neutral'\n",
        "    df.loc[df.Polarity < 0,'Sentiment'] = 'negative'\n",
        "    \n",
        "    return df[['tweet','tweetNew','Polarity','Subjectivity','Sentiment']].head()\n",
        "\n"
      ],
      "metadata": {
        "id": "oeKSDkE6H5VS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "l-ze-ZJ_APOh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}